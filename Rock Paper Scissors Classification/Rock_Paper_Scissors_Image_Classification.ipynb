{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rock Paper Scissors Image Classification  ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Deep Learning Image Classification using Neural Network**\n",
        "<br> by \n",
        "Matan-Ben Nagar\n",
        "&\n",
        "Yaara Kresner-Barak"
      ],
      "metadata": {
        "id": "UiGY1xBHaYiU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTMs24Y1gEEG"
      },
      "source": [
        "## Importing our libraries for the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTC_pP87gIkG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Flatten,Conv2D,MaxPool2D,Dropout,AveragePooling2D\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj-hCwENhrQ-"
      },
      "source": [
        "## Load rock_paper_scissors dataset\n",
        "The dataset contains 2892 images of hands playing rock, paper, scissor game.\n",
        "Its have two features- image (300, 300, 3) and lable.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-DCEGhnh_4m",
        "collapsed": true
      },
      "source": [
        "##import the dataset from tensorflow_datasets library \n",
        "builder = tfds.builder('rock_paper_scissors')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxzo48KfiiGH"
      },
      "source": [
        "Split Rock, Paper, Scissors data\n",
        "The train set contains 2520 images, and the test set contains 372 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNfZOqrcioeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02cf4eb8-cf3c-4891-e1e7-c105ab91da8d"
      },
      "source": [
        "#load the train and test sets from the DB \n",
        "ds_train = tfds.load(name=\"rock_paper_scissors\", split=\"train\")\n",
        "ds_test = tfds.load(name=\"rock_paper_scissors\", split=\"test\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset rock_paper_scissors/3.0.0 (download: 219.53 MiB, generated: Unknown size, total: 219.53 MiB) to /root/tensorflow_datasets/rock_paper_scissors/3.0.0...\u001b[0m\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/rock_paper_scissors/3.0.0.incomplete6PAHF7/rock_paper_scissors-train.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/rock_paper_scissors/3.0.0.incomplete6PAHF7/rock_paper_scissors-test.tfrecord\n",
            "\u001b[1mDataset rock_paper_scissors downloaded and prepared to /root/tensorflow_datasets/rock_paper_scissors/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the tensorflow dataset format into numpy format,\n",
        "\n",
        "Create numpy arrays that contains the images and the labels separately,\n",
        "\n",
        "And change the images three color channels RGB format to one color channel (to reduce the unimportant data)\n"
      ],
      "metadata": {
        "id": "hhRqwjTi-XdZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOahag-mjuof"
      },
      "source": [
        "train_images = np.array([example['image'].numpy()[:,:,0] for example in ds_train])\n",
        "train_labels = np.array([example['label'].numpy() for example in ds_train])\n",
        "\n",
        "test_images = np.array([example['image'].numpy()[:,:,0] for example in ds_test])\n",
        "test_labels = np.array([example['label'].numpy() for example in ds_test])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping the images to 300 x 300 x 1 (add color feature- grayscale images). "
      ],
      "metadata": {
        "id": "cnv8_A23JUbS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg56AOko4qby"
      },
      "source": [
        "train_images = train_images.reshape(2520, 300, 300, 1)\n",
        "test_images = test_images.reshape(372, 300, 300, 1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting us ready to be able to convert it from a scale of 0 to 1\n",
        "instead of 0 to 255\n"
      ],
      "metadata": {
        "id": "zLob8ZC5JgOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')"
      ],
      "metadata": {
        "id": "A7Ra1QAUJhO6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Normalize the Data\n",
        "Train images dividing equal by 255,\n",
        "So the max value we can have is 255 because RGB values are between 0 and 255 so by doing this we're scaling every value to be between 0 & 1 and this is just a good common practice that helps you classify it.\n",
        "It helps the basically network learn better than if you use the 0 to 255 values you could leave it 0 to 255 but it's just ultimately it's gonna probably decrease your performance a bit, so it's a common step to normalize between 0 & 1.\n"
      ],
      "metadata": {
        "id": "trL1RIfDJ0hW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGgO23W14xB9"
      },
      "source": [
        "train_images /= 255\n",
        "test_images /= 255"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic regression\n"
      ],
      "metadata": {
        "id": "KyHhtZlyiSe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output layer.\n",
        "model_lr = keras.Sequential([\n",
        "   keras.layers.Flatten(),\n",
        "   keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "rmsprop_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "\n",
        "model_lr.compile(\n",
        "    optimizer=rmsprop_optimizer,\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model_lr.fit(train_images, train_labels, epochs=5, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IzLCOnmiYKC",
        "outputId": "9931b098-0d7a-4f0d-c577-3bd4a9b8673b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "79/79 [==============================] - 3s 9ms/step - loss: 54.2391 - accuracy: 0.3706\n",
            "Epoch 2/5\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 41.1307 - accuracy: 0.3873\n",
            "Epoch 3/5\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 33.5964 - accuracy: 0.4583\n",
            "Epoch 4/5\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 28.1765 - accuracy: 0.5083\n",
            "Epoch 5/5\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 26.2074 - accuracy: 0.5464\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f653d925d10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr.evaluate(test_images, test_labels)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkG3jyuijLbv",
        "outputId": "7ad4ab5c-d49e-452f-b995-688206144b0f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 8ms/step - loss: 49.3277 - accuracy: 0.3414\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[49.32766342163086, 0.34139785170555115]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM_SDKpFBpGs"
      },
      "source": [
        "##MLP "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model network layer transform the 300 by 300 image into single colum,\n",
        "After that we have two layers of activation relu function- because the constant gradient of ReLUs results in faster learning.\n",
        "Finally ,the output layer going to be the same size as the number of labels we trying to classify- we use softmax because it efficient in classification problems. "
      ],
      "metadata": {
        "id": "J_QAMuu0FNxM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pULotR1OPZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d4bfda-d8ba-4198-d58c-b607bfb53731"
      },
      "source": [
        "model = keras.Sequential([\n",
        "  Flatten(),\n",
        "  Dense(512, activation='relu'),\n",
        "  Dense(256, activation='relu'),\n",
        "  Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "#setup loss function\n",
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#fit our data to the model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=32)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "79/79 [==============================] - 3s 28ms/step - loss: 24.8398 - accuracy: 0.4405\n",
            "Epoch 2/5\n",
            "79/79 [==============================] - 2s 27ms/step - loss: 1.8433 - accuracy: 0.6310\n",
            "Epoch 3/5\n",
            "79/79 [==============================] - 2s 27ms/step - loss: 0.9661 - accuracy: 0.7579\n",
            "Epoch 4/5\n",
            "79/79 [==============================] - 2s 27ms/step - loss: 0.7866 - accuracy: 0.7948\n",
            "Epoch 5/5\n",
            "79/79 [==============================] - 2s 27ms/step - loss: 1.5869 - accuracy: 0.6917\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f64c3f73710>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkA2gAtmO88d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b026597b-3bb5-401a-8497-cc4f7482eee0"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 13ms/step - loss: 2.0530 - accuracy: 0.4758\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.053011417388916, 0.47580644488334656]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we overfitting to our data - the model not learning the train data. \n",
        "we can see it by the results- the accuracy in the train data is 0.89 and the accuracy in the test data is 0.44."
      ],
      "metadata": {
        "id": "8R8uA0KfIaAs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J6Q2DJ6hX7c"
      },
      "source": [
        "##Convolutional Neural Network\n",
        "This time the first layer will be Conv2D()  because the dataset consist of 2D images. The first variable inserted in the function is basically how many times a smaller gird is passing over the image <br>\n",
        "this is how big or smaller grid is so if I said three and I didn't pass in three to start off and we'll leave the rides at one two one that just means they'll move one every time so it's gonna be a sliding window of three by three "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UNpaMMJpJRT",
        "outputId": "b669b33a-641b-4dfd-9b1e-478811760493"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 98 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.0 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instructions and exmaples of how to use Keras Tuner can be found in here \n",
        "# https://keras.io/keras_tuner/\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "def build_model(hp):\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  model.add(AveragePooling2D(6,3,input_shape=(300,300,1)))\n",
        "\n",
        "  model.add(Conv2D(64,3,activation='relu'))\n",
        "  model.add(Conv2D(32,3,activation='relu'))\n",
        "\n",
        "  model.add(MaxPool2D(2,2))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Flatten())\n",
        "  #hp.Choise function will allow us to test out different variables for this dense layer \n",
        "  model.add(Dense(hp.Choice(\"Dense layer\", [64, 128, 256, 512, 1024,2048]), activation='relu'))\n",
        "\n",
        "  model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "# randomSearch will run random combination we insert into the model until it reaches the max_trials or until all of the trials are done.\n",
        "# the tuner will result in giving an array of models with different combination from the one which performed highest to the lowest\n",
        "# we can get the models by using tuner.get_best_model()\n",
        "tuner = RandomSearch(\n",
        "    # calling the build model function\n",
        "    build_model, \n",
        "    # our objective is the validation accuracy - how well will it do on our test set?\n",
        "    objective='val_accuracy',\n",
        "    max_trials=8,\n",
        ")\n",
        "# what are we trying to optimise this network for? validation_data\n",
        "tuner.search(train_images, train_labels, validation_data=(test_images, test_labels), epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBXxml2mpRiA",
        "outputId": "19f2fbee-8e91-4214-f54d-e397b81700ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 13 Complete [00h 00m 42s]\n",
            "val_accuracy: 0.725806474685669\n",
            "\n",
            "Best val_accuracy So Far: 0.8064516186714172\n",
            "Total elapsed time: 00h 13m 57s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_models()[0].evaluate(test_images,test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqgJN4oruh1y",
        "outputId": "ff3836b3-0011-4a67-d68e-6e3dfb3aa72e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 1s 29ms/step - loss: 0.6035 - accuracy: 0.8065\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6035187244415283, 0.8064516186714172]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}